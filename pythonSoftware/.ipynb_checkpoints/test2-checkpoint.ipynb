{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense,LSTM,Dropout, Activation\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1225 entries, 0 to 1224\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Date       1225 non-null   object \n",
      " 1   Open       1220 non-null   float64\n",
      " 2   High       1220 non-null   float64\n",
      " 3   Low        1220 non-null   float64\n",
      " 4   Close      1220 non-null   float64\n",
      " 5   Adj Close  1220 non-null   float64\n",
      " 6   Volume     1220 non-null   float64\n",
      "dtypes: float64(6), object(1)\n",
      "memory usage: 67.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1220.000000</td>\n",
       "      <td>1220.000000</td>\n",
       "      <td>1220.000000</td>\n",
       "      <td>1220.000000</td>\n",
       "      <td>1220.000000</td>\n",
       "      <td>1.220000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>43534.352459</td>\n",
       "      <td>43976.032787</td>\n",
       "      <td>43095.516393</td>\n",
       "      <td>43537.147541</td>\n",
       "      <td>29540.297660</td>\n",
       "      <td>1.330320e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10035.454695</td>\n",
       "      <td>10118.881700</td>\n",
       "      <td>9897.118173</td>\n",
       "      <td>9996.711653</td>\n",
       "      <td>21373.508835</td>\n",
       "      <td>7.227672e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>21760.000000</td>\n",
       "      <td>22660.000000</td>\n",
       "      <td>21760.000000</td>\n",
       "      <td>22520.000000</td>\n",
       "      <td>254.533798</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>37260.000000</td>\n",
       "      <td>37895.000000</td>\n",
       "      <td>37015.000000</td>\n",
       "      <td>37457.500000</td>\n",
       "      <td>7920.729126</td>\n",
       "      <td>8.809462e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>45900.000000</td>\n",
       "      <td>46355.000000</td>\n",
       "      <td>45460.000000</td>\n",
       "      <td>45875.000000</td>\n",
       "      <td>39964.230470</td>\n",
       "      <td>1.143096e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>50500.000000</td>\n",
       "      <td>50900.000000</td>\n",
       "      <td>49900.000000</td>\n",
       "      <td>50355.000000</td>\n",
       "      <td>47694.547852</td>\n",
       "      <td>1.535945e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>62000.000000</td>\n",
       "      <td>62800.000000</td>\n",
       "      <td>61700.000000</td>\n",
       "      <td>62400.000000</td>\n",
       "      <td>62400.000000</td>\n",
       "      <td>6.468130e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Open          High           Low         Close     Adj Close  \\\n",
       "count   1220.000000   1220.000000   1220.000000   1220.000000   1220.000000   \n",
       "mean   43534.352459  43976.032787  43095.516393  43537.147541  29540.297660   \n",
       "std    10035.454695  10118.881700   9897.118173   9996.711653  21373.508835   \n",
       "min    21760.000000  22660.000000  21760.000000  22520.000000    254.533798   \n",
       "25%    37260.000000  37895.000000  37015.000000  37457.500000   7920.729126   \n",
       "50%    45900.000000  46355.000000  45460.000000  45875.000000  39964.230470   \n",
       "75%    50500.000000  50900.000000  49900.000000  50355.000000  47694.547852   \n",
       "max    62000.000000  62800.000000  61700.000000  62400.000000  62400.000000   \n",
       "\n",
       "             Volume  \n",
       "count  1.220000e+03  \n",
       "mean   1.330320e+07  \n",
       "std    7.227672e+06  \n",
       "min    0.000000e+00  \n",
       "25%    8.809462e+06  \n",
       "50%    1.143096e+07  \n",
       "75%    1.535945e+07  \n",
       "max    6.468130e+07  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('../dataset/005930.KS.csv', sep=',')\n",
    "\n",
    "data = dataset.dropna()\n",
    "\n",
    "dataset.head()\n",
    "dataset.info()\n",
    "dataset.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Close\n",
      "0     0.083250\n",
      "1     0.086259\n",
      "2     0.091274\n",
      "3     0.099799\n",
      "4     0.123370\n",
      "...        ...\n",
      "1215  0.939819\n",
      "1216  0.962387\n",
      "1217  0.962387\n",
      "1218  0.942327\n",
      "1219  0.944835\n",
      "\n",
      "[1220 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# scale_cols = ['Close']\n",
    "# df_scaled = scaler.fit_transform(data[scale_cols])\n",
    "\n",
    "# df_scaled = pd.DataFrame(df_scaled)\n",
    "# df_scaled.columns = scale_cols\n",
    "# print(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data[['Close']]\n",
    "df.shape\n",
    "df=np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1199, 21, 1)\n"
     ]
    }
   ],
   "source": [
    "sequen_len=20\n",
    "seq_len =sequen_len+1\n",
    "\n",
    "\n",
    "windows=[]\n",
    "x=[]\n",
    "y=[]\n",
    "for i in range(len(df)-seq_len):\n",
    "    windows.append(df[i:i+seq_len])\n",
    "\n",
    "windows = np.array(windows)\n",
    "print(windows.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data = []\n",
    "for win in windows:\n",
    "    normalized_window = [(float(p) - float(min(win))) / (float(max(win)) - float(min(win))) for p in win]\n",
    "    normalized_data.append(normalized_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-..정규화\n",
    "# normalized_data = []\n",
    "# for win in windows:\n",
    "#     normalized_window = [(float(p) - float(np.mean(win)) / float(np.std(win))) for p in win]\n",
    "#     normalized_data.append(normalized_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# df_scaled = scaler.fit_transform(windows)\n",
    "\n",
    "# df_scaled = pd.DataFrame(df_scaled)\n",
    "\n",
    "# print(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.375     ]\n",
      " [0.51666667]\n",
      " [0.90833333]\n",
      " [1.        ]\n",
      " [0.74166667]\n",
      " [0.55833333]\n",
      " [0.65833333]\n",
      " [0.625     ]\n",
      " [0.675     ]\n",
      " [0.48333333]\n",
      " [0.58333333]\n",
      " [0.45      ]\n",
      " [0.30833333]\n",
      " [0.        ]\n",
      " [0.05833333]\n",
      " [0.15      ]\n",
      " [0.21666667]\n",
      " [0.18333333]\n",
      " [0.15833333]\n",
      " [0.3       ]]\n",
      "0.3\n"
     ]
    }
   ],
   "source": [
    "windows = np.array(normalized_data)\n",
    "\n",
    "x = windows[:,:-1]\n",
    "x = np.reshape(x,(x.shape[0], x.shape[1],1))\n",
    "y = windows[:,-1]\n",
    "\n",
    "x = np.array(x)\n",
    "\n",
    "\n",
    "\n",
    "print(x[2])\n",
    "print(y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.2, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_51 (LSTM)               (None, 20, 60)            14880     \n",
      "_________________________________________________________________\n",
      "lstm_52 (LSTM)               (None, 20, 50)            22200     \n",
      "_________________________________________________________________\n",
      "lstm_53 (LSTM)               (None, 20, 32)            10624     \n",
      "_________________________________________________________________\n",
      "lstm_54 (LSTM)               (None, 20)                4240      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 51,965\n",
      "Trainable params: 51,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(60, return_sequences=True, input_shape=(x.shape[1],x.shape[2])))\n",
    "model.add(LSTM(50, return_sequences=True))\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(20, return_sequences=False))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "es = EarlyStopping(monitor='val_loss', patience=5)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='auto', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "95/96 [============================>.] - ETA: 0s - loss: 0.0741\n",
      "Epoch 00001: val_loss did not improve from 0.07045\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0741 - val_loss: 0.0760\n",
      "Epoch 2/1000\n",
      "94/96 [============================>.] - ETA: 0s - loss: 0.0774\n",
      "Epoch 00002: val_loss improved from 0.07045 to 0.06615, saving model to best_model.h5\n",
      "96/96 [==============================] - 3s 31ms/step - loss: 0.0769 - val_loss: 0.0662\n",
      "Epoch 3/1000\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0687\n",
      "Epoch 00003: val_loss improved from 0.06615 to 0.05651, saving model to best_model.h5\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0687 - val_loss: 0.0565\n",
      "Epoch 4/1000\n",
      "95/96 [============================>.] - ETA: 0s - loss: 0.0582\n",
      "Epoch 00004: val_loss did not improve from 0.05651\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0585 - val_loss: 0.0649\n",
      "Epoch 5/1000\n",
      "95/96 [============================>.] - ETA: 0s - loss: 0.0437\n",
      "Epoch 00005: val_loss improved from 0.05651 to 0.03999, saving model to best_model.h5\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0435 - val_loss: 0.0400\n",
      "Epoch 6/1000\n",
      "95/96 [============================>.] - ETA: 0s - loss: 0.0364\n",
      "Epoch 00006: val_loss improved from 0.03999 to 0.03702, saving model to best_model.h5\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0363 - val_loss: 0.0370\n",
      "Epoch 7/1000\n",
      "95/96 [============================>.] - ETA: 0s - loss: 0.0345\n",
      "Epoch 00007: val_loss did not improve from 0.03702\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0347 - val_loss: 0.0373\n",
      "Epoch 8/1000\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0343\n",
      "Epoch 00008: val_loss improved from 0.03702 to 0.03484, saving model to best_model.h5\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0343 - val_loss: 0.0348\n",
      "Epoch 9/1000\n",
      "95/96 [============================>.] - ETA: 0s - loss: 0.0348- ETA: 0s - loss: 0.0\n",
      "Epoch 00009: val_loss did not improve from 0.03484\n",
      "96/96 [==============================] - 3s 32ms/step - loss: 0.0348 - val_loss: 0.0353\n",
      "Epoch 10/1000\n",
      "95/96 [============================>.] - ETA: 0s - loss: 0.0336\n",
      "Epoch 00010: val_loss improved from 0.03484 to 0.03442, saving model to best_model.h5\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0336 - val_loss: 0.0344\n",
      "Epoch 11/1000\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0327\n",
      "Epoch 00011: val_loss improved from 0.03442 to 0.03330, saving model to best_model.h5\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0327 - val_loss: 0.0333\n",
      "Epoch 12/1000\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0343\n",
      "Epoch 00012: val_loss did not improve from 0.03330\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0343 - val_loss: 0.0341\n",
      "Epoch 13/1000\n",
      "95/96 [============================>.] - ETA: 0s - loss: 0.0339\n",
      "Epoch 00013: val_loss did not improve from 0.03330\n",
      "96/96 [==============================] - 3s 29ms/step - loss: 0.0340 - val_loss: 0.0344\n",
      "Epoch 14/1000\n",
      "95/96 [============================>.] - ETA: 0s - loss: 0.0328\n",
      "Epoch 00014: val_loss did not improve from 0.03330\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0330 - val_loss: 0.0344\n",
      "Epoch 15/1000\n",
      "95/96 [============================>.] - ETA: 0s - loss: 0.0328\n",
      "Epoch 00015: val_loss did not improve from 0.03330\n",
      "96/96 [==============================] - 3s 30ms/step - loss: 0.0329 - val_loss: 0.0430\n",
      "Epoch 16/1000\n",
      "96/96 [==============================] - ETA: 0s - loss: 0.0330\n",
      "Epoch 00016: val_loss did not improve from 0.03330\n",
      "96/96 [==============================] - 3s 28ms/step - loss: 0.0330 - val_loss: 0.0341\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train, Y_train, validation_data=(X_test, Y_test), callbacks=[es, mc], batch_size=10, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
